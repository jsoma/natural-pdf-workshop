{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Install required packages\n",
    "!pip install --upgrade --quiet natural-pdf[ocr-export,ai]\n",
    "!pip install --upgrade --quiet easyocr\n",
    "!pip install --upgrade --quiet surya-ocr\n",
    "\n",
    "print('\u2713 Packages installed!')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Slides:** [slides.pdf](./slides.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7607b3ac-3d41-454c-88e0-f096db6a3c67",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# OCR: Recognizing text\n",
    "\n",
    "Sometimes you can't actually get the text off of the page. It's an *image* of text instead of being actual text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794f6224-1ec2-497e-be92-83cb65c8e192",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from natural_pdf import PDF\n",
    "\n",
    "pdf = PDF(\"https://github.com/jsoma/natural-pdf/raw/refs/heads/main/pdfs/needs-ocr.pdf\")\n",
    "page = pdf.pages[0]\n",
    "page.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdd7508-24f5-4ba6-b8f6-bc82bc4c3e0e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Looks the same as the last one, right? But when we try to extract the text..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72673727-f6cc-4db2-aba9-4da3145a83ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = page.extract_text()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798cca14",
   "metadata": {},
   "source": [
    "Nothing! **It's time for OCR.**\n",
    "\n",
    "There are a looooot of OCR engines out there, and one of the things that makes Natural PDF nice is that it supports multiples. Figuring out which one is the \"best\" isn't as tough when you can just run them all right after each other.\n",
    "\n",
    "The default is [EasyOCR](https://github.com/JaidedAI/EasyOCR) which usually works fine. But what happens when we try it with this document?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8331e71a",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "page.apply_ocr()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "168cd4de",
   "metadata": {},
   "source": [
    "It does pretty well! The only issue is it gives me **Durham's Pure Leaf Lardl** instead of **Durham's Pure Leaf Lard!** I don't need to know why, though, really, because I can just try some other engine! You can also fool around with the options - some of the the lowest-hanging fruit is increasing the resolution of the OCR. The default at the moment is 150, you can try upping to 300 for (potentially) better results.\n",
    "\n",
    "To fix this I'll both up the resolution and try another OCR engine, [surya](https://github.com/datalab-to/surya)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "247fc19a-606e-4296-bc07-0f173de872b5",
   "metadata": {},
   "source": [
    "## Correcting OCR\n",
    "\n",
    "While we love OCR when it works, it often does *not* work great. We have a few solutions: send humans after it, or use LLMs or spell check to correct it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bee0fd5-7285-4f00-b697-ce55e2d10dcd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from natural_pdf import PDF\n",
    "\n",
    "pdf = PDF(\"https://github.com/jsoma/natural-pdf/raw/refs/heads/main/pdfs/needs-ocr.pdf\")\n",
    "\n",
    "page = pdf.pages[0]\n",
    "# We'll OCR this with the worst possible resolution\n",
    "page.apply_ocr('surya', resolution=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a1c610-8af5-4354-99c2-59f6d70c42f9",
   "metadata": {},
   "source": [
    "After we apply OCR we can export to a magic format that we can display and fix up separately!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f03719-4bdb-4b32-acd6-948e426e2621",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = page.extract_text()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffdfdbc-1ac5-4f6f-b107-3659ff94bf06",
   "metadata": {},
   "source": [
    "### With LLMs\n",
    "\n",
    "Let's see what our text looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db998c49-3c94-4332-974c-fb68ad2105a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "page.find_all('text').inspect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa7ac43-5869-4e25-bd67-a8f1333d7001",
   "metadata": {},
   "source": [
    "Some of these are pretty easy - for example, \"Uraanitary Warking Conditions\" should be \"Unsanity working conditions.\" OCR tools just don't know that kind of thing! But what if we could go through each piece of text, some some sort of spell check or something?\n",
    "\n",
    "You can use `correct_ocr` to change the text in a region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c3ef62-1286-4a92-986c-9cdf6e96a285",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def correct_text_region(region):\n",
    "    return \"This is the updated text\"\n",
    "    \n",
    "page.correct_ocr(correct_text_region) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba0ed4c-c888-4568-9435-7a1738544c75",
   "metadata": {},
   "source": [
    "And then, magically, all of our text is whatever we `return`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e06572-839b-4d30-99f5-9eeb843d7476",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "page.find_all('text').inspect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bda455d-77ab-4335-b3a5-ea9e7a0cd9ee",
   "metadata": {},
   "source": [
    "But clearly we don't want the same thing every time! Let's add the bad OCR back in..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64271e8-595a-41e3-9f63-19c58449a4a4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Re-apply the OCR to break it again\n",
    "page.apply_ocr('surya', resolution=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa501818-7ff9-43e3-9ad9-218417360482",
   "metadata": {},
   "source": [
    "...and feed each line to an LLM trying to fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817914da-0583-43f3-bbee-e701ac94a194",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from natural_pdf.ocr.utils import direct_ocr_llm\n",
    "\n",
    "client = OpenAI(api_key='sk-proj--......')\n",
    "\n",
    "prompt = \"\"\"\n",
    "Correct the spelling of this OCR'd text, a snippet of a document.\n",
    "Preserve original capitalization, punctuation, and symbols. \n",
    "Changing meaning is okay if it's clearly an OCR issue.\n",
    "Do not add any explanatory text, translations, comments, or quotation marks around the result.\n",
    "\"\"\"\n",
    "\n",
    "def correct_text_region(region):\n",
    "    text = region.extract_text()\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-nano\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\", \"content\": prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": text\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    updated = completion.choices[0].message.content\n",
    "\n",
    "    if text != updated:    \n",
    "        print(f\"OLD: {text}\\nNEW:{updated}\") \n",
    "\n",
    "    return updated\n",
    "\n",
    "page.correct_ocr(correct_text_region) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34553785-0ce9-446f-b922-8ded673e24ae",
   "metadata": {},
   "source": [
    "And now we can use `.extract_text()` the magicaly same way.\n",
    "\n",
    "The real benefit of this vs sending the whole document to the LLM is *we don't change where the text is*. An LLM might OCR something for us, but it *loses the spatial context that we find so important*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae0d23a-877e-422f-8636-b0960bb84463",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = page.extract_text()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d2e0c6-5a42-44fd-9827-924453ee354c",
   "metadata": {},
   "source": [
    "## Let's do the OCR with the LLM, period\n",
    "\n",
    "But if the LLM is *that good* at OCR, we can also find pieces of the page we would like to OCR and *send them each in isolation to the LLM*. We use `detect_only=True` so it doesn't try to figure out what the text is, just that the text is there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98294bd-fbd4-4222-b47a-997830c37b05",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "page.apply_ocr('surya', detect_only=True)\n",
    "page.find_all('text').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6f9638-2bc4-4b72-82e7-81ffb4ddf49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "page.find_all('text').inspect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca61c72-d112-457d-85a8-19bb22ff7ad5",
   "metadata": {},
   "source": [
    "Now we'll do an even fancier `correct_text_region`: it takes the region as an image, and sends it right on over to the LLM for OCR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca814b89-bd2f-4a4e-8da4-7d2b5d9af006",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from natural_pdf.ocr.utils import direct_ocr_llm\n",
    "\n",
    "client = OpenAI(api_key='API_KEY_GOES_HERE')\n",
    "\n",
    "prompt = \"\"\"OCR this image patch. Return only the exact text content visible in the image. \n",
    "Preserve original spelling, capitalization, punctuation, and symbols.\n",
    "Fix misspellings if they are the result of blurry or incorrect OCR.\n",
    "Do not add any explanatory text, translations, comments, or quotation marks around the result.\n",
    "If you cannot process the image or do not see any text, return an empty space.\n",
    "The text is from an inspection report of a slaughterhouse.\"\"\"\n",
    "# The text is likely from a Greek document, potentially a spreadsheet, containing Modern Greek words or numbers\n",
    "\n",
    "def correct_text_region(region):\n",
    "    # Use a high resolution for the LLM call for best accuracy\n",
    "    return direct_ocr_llm(\n",
    "        region, \n",
    "        client, \n",
    "        prompt=prompt, \n",
    "        resolution=150, \n",
    "        model=\"gpt-4o\" \n",
    "    )\n",
    "\n",
    "page.correct_ocr(correct_text_region) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d108124-f9bf-4148-a902-5772a149b1ec",
   "metadata": {},
   "source": [
    "What do we have now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150ad115-f770-4d37-b57b-b6bf78ed2dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "page.find_all('text').inspect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6390d453-90f1-421b-b92a-2c14df1502ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = page.extract_text()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3810c680-f509-4e2c-b1f7-ac5a33a4e29f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Finding tables on OCR documents\n",
    "\n",
    "When we used `page.extract_table()` last time, it was easy because there were all of these `line` elements on the page that pdfplumber could detect and say \"hey, it's a table!\" For the same reason that there's no *real* text on the page, there's also no *real* lines on the page. Instead, we're going to do a fun secret trick where we look at what horizontal and vertical coordinates *seem* like they might be lines by setting a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86b94bd-c2ae-4f7b-9dfd-76bfc18787be",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from natural_pdf import PDF\n",
    "\n",
    "pdf = PDF(\"https://github.com/jsoma/natural-pdf/raw/refs/heads/main/pdfs/needs-ocr.pdf\")\n",
    "page.apply_ocr()\n",
    "page.show(width=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fcfb0a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "table_area = (\n",
    "    page\n",
    "    .find('text:contains(Violations)')\n",
    "    .below(\n",
    "        until='text:contains(Jungle)',\n",
    "        include_endpoint=False\n",
    "    )\n",
    ")\n",
    "table_area.show(crop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a5f1d1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from natural_pdf.analyzers.guides import Guides\n",
    "\n",
    "guides = Guides(table_area)\n",
    "guides.vertical.from_lines(threshold=0.4)\n",
    "guides.horizontal.from_lines()\n",
    "guides.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4ddfc9-c592-4f6c-be97-2ef1c5917351",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Now we can add the lines and use them to detect the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e014c89",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = guides.extract_table().to_df()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9b673c-12a2-4697-a245-68aefe282ee5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Figuring out information about things that are *not* text\n",
    "\n",
    "In a tiny preview of the next notebook: **what about those checkboxes?** Turns out we can use **image classification AI** to do it for us in the next notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6854779a-daf9-4186-b057-5d3311675a1f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "workshop": {
   "description": "Some PDFs are just images of text instead of being actual text. This is when you need OCR (optical character recognition).",
   "install": [
    "natural-pdf[ocr-export,ai]",
    "easyocr",
    "surya-ocr"
   ],
   "links": [
    {
     "name": "Surya OCR",
     "url": "https://github.com/datalab-to/surya"
    },
    {
     "name": "EasyOCR",
     "url": "https://github.com/JaidedAI/EasyOCR"
    },
    {
     "name": "PaddleOCR",
     "url": "https://www.paddleocr.ai/latest/en/index.html"
    }
   ],
   "order": 2,
   "title": "Recognizing text with OCR engines using Natural PDF",
   "slides": "slides.pdf"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}